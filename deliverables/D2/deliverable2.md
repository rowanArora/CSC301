# Group 19 - mhapy D2

## 1. Summary of Software
Our product is a sentiment analysis machine learning model trained on text data scraped from the mhapy app.
Since they have data that is not being used our solution involves building a text scraping API to extract data from both user prompts to the AI chatbot and personal journals. This data will be used to train a machine learning model capable of performing sentiment analysis. Once trained, the model will be integrated into an API, enabling real-time sentiment analysis of new text data from the app. Users can receive insights into whether their text is positive or negative and access scatter plot graphs displaying weekly trends. In cases of persistently negative trends, notifications can be sent to the user, an accountability buddy, or a therapist.

### a. For problem & partner
Partnered with mhapy, an online therapy solution, we address the challenge of underutilized text data collected from users of their app. Mhapy employs AI chatbots and personal journaling to assist users in managing their mental health. Users can interact with a chatbot for therapy sessions or use the app as a virtual journal. Both these offer a convenient solution to users seeking mental health solutions with anonymity and/or affordably. They also are planning to sell this app to other therapists to implement it within their website to better serve their clients using this digital solution. The problem they face is that they have a lot of unutilized data within their app. Through journal entries and user input to their ai chat bot they have a lot of user text data that relates to mental. They need something that will take this data to learn a model that can predict sentiment on new mental health related data. With this they can send users analytics based on how they are typing within the app to help improve their mental health long term by using more positive phrases. While also being able to track their progress and receive notifications if they are seen to be using too many negative words.

### b. Existing software/infrastructure
Our partner's app, available on the Play Store and App Store, collects text data from its users and stores it in a database hosted on Google Cloud Platform (GCP). To ensure redundancy and support our needs, our partner is in the process of duplicating this database onto Amazon Web Services (AWS) where we plan to deploy our API. However, they are currently facing delays in duplicating the database, which means that access to this critical data source won't be available for our deliverable 2. So we will have to use other means to deploy and test our deliverables.

## 2. Division of Project

In splitting the project into three main components - the API for data retrieval and preprocessing, the machine learning model for sentiment analysis, and the visualization component for displaying user sentiment trends over time - careful consideration was given to promoting modularity, scalability, and maintainability, while aligning with the requirements of the partner. This design allows for efficient collaboration among team members, facilitates future upgrades, and minimizes the risk of single-point failures.

The first component, the API, was chosen as the foundational layer as it serves as the interface for accessing and manipulating the user's text data. By separating data retrieval from the other stages, we achieve a clear separation of concerns and allow for multiple data sources to be integrated seamlessly in the future. This API connects to a database where user text data is stored, retrieves the necessary data, and preprocesses it, cleansing it of any irrelevant or noise-creating information.

The second component, the machine learning model, is where the sentiment analysis takes place. By separating this from the API layer, we can focus on the specific task of analyzing the user's text data and developing and training the machine learning model. This model can then be fine-tuned and updated independently, without affecting the other components, which is crucial when needing to retrain and update the model in the future. Scalability is an important factor for our project.

The final component, the visualization layer, is responsible for presenting the analyzed data in a user-friendly manner. It takes the sentiment scores generated by the machine learning model and plots them on a graph over a specified time period. This separation ensures that the visualization can be adapted to different user interfaces and preferences without affecting the core sentiment analysis and data retrieval functionality.

To illustrate the architectural layout, consider a diagram where the API layer connects to the database and the machine learning model, while the visualization component receives data from the model. Each component is relatively self-contained, and this modular design allows for flexibility and scalability as the project evolves. In sum, dividing the project into these three components ensures maintainability, extensibility, and robustness, making it easier to adapt to changes and enhancements in the future. 

<p align="center">
  <img src="/deliverables/D2/resources/D2 Diagram CSC301.png" alt="Mockup Flow Diagram">
</p>

Here is a link to the actual diagram:

https://lucid.app/lucidchart/7939ce53-5fd7-45b6-a340-75b7ae154340/edit?invitationId=inv_a0079ec1-0088-4b72-860c-0d8638abd525&page=0_0#

## 3. One paragraph for part(s) each sub-team is responsible for.

### 19.1 (Machine Learning Model)
We are responsible for the sub-project that handles sentiment analysis. We made the informed decision to utilize a Bidirectional Long Short-term memory model (BiLSTM) for the sentiment analysis sub-project. We considered other machine learning models, in particular, a Bayesian classifier. After some discussion and shared insight, we decided on settling on a BiLSTM model, since it has common application in natural language processing and even sentiment analysis. We obtained a dataset from Kaggle which has conveniently already labeled tweets from Twitter as potential suicide posts or not. We will be using this dataset to train our model.

### 19.2 (Visualization)
Our team’s responsibility was the visualization of sentiment analysis data. With no actual sentiment data to plot yet, we first had to create custom test data in csv format via a python script. We then had to take this data and process it into a format that would be turned into a plotly graph. Later, this plotly graph will be sent back to the user via the API, but for now we deployed it onto a web server via Render.

### 19.3 (Database API + Text Preprocessing)
Our team is responsible for creating an API that connects to the database to retrieve data that has been scraped from mhapy’s app. After getting the data we run a python script to clean and preprocess the data and print the cleaned text to standard out where the API converts it back to a csv. This csv will be later passed to the machine learning model so it can be trained on the data. We are also responsible for the containerization of the API and deploying it to a Render.com server. We also integrated the app through CI/CD through GitHub Actions workflows to continuously develop, test and deploy our API.



